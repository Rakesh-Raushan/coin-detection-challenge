# YOLOv8n Fine-tuning for Coin Detection

Fine-tune YOLOv8n on the coin detection dataset to improve over the off-the-shelf baseline.

## Baseline Performance (off-the-shelf yolov8n)

| Metric | Value |
|---|---|
| mAP@0.5:0.95 | 0.5011 |
| mAP@0.5 | 0.5565 |
| Count Accuracy | 0.4231 |
| Mean Abs Count Error | 1.27 |

## Quick Start

```bash
# 1. Prepare dataset (3-way stratified split → train/val as YOLO, test as COCO)
python scripts/prepare_dataset.py

# 2. Train
python scripts/train.py --name baseline-finetune

# 3. Evaluate on held-out test set (final reporting)
python scripts/evaluate.py experiments/<exp_dir>/train/weights/best.pt --test

# 4. Export best model to artifacts/
python scripts/export_model.py experiments/<exp_dir>
```

## Data Split Strategy

The dataset (191 images) is split **before** any format conversion:

| Split | Size | Format | Purpose |
|-------|------|--------|---------|
| Train | 139 (73%) | YOLO | Model training |
| Val | 26 (14%) | YOLO | Early stopping + checkpoint selection |
| Test | 26 (14%) | COCO | Final performance reporting (never seen during training) |

- Stratified by annotation count (bins: 1, 2, 3, 4+) so each split has representative coin-count distribution
- Test set stays in COCO format because the evaluator consumes COCO natively
- Deterministic split (seed=42) for reproducibility


### Training Configuration Summary

YOLOv8n, Nano model was considered as the sufficient candidate for single-class coin detection and favoured for small size ~6MB for deployment, it also benefits from COCO pretraining.

| Component | Setting | Rationale |
|-----------|---------|-----------|
| **Learning Rate** | `lr0=0.001`, `lrf=0.01`, `cos_lr=True`, `warmup_epochs=5` | Low initial LR preserves pretrained features; cosine decay for smooth convergence; warmup prevents early instability. |
| **Early Stopping** | `patience=15` | Avoid overfitting on small dataset (139 images), allows sufficient cosine phases before halting. |
| **Optimizer & Weight Decay** | `AdamW`, `0.0005` | Stable gradient updates; mild regularization to prevent overfitting. |
| **Rotation / Scale / Flip** | ±15°, 0.5–1.5×, horiz 50%, vert 0% | Small rotations handle tilt; scale handles distance variation; flips realistic for symmetric coins. |
| **Color Augmentation** | `hsv_h=0.015`, `hsv_s=0.7`, `hsv_v=0.4` | Handles reflections, lighting variation; conservative hue preserves coin identity. |
| **Mosaic & MixUp** | Mosaic 100%, Close Mosaic last 10 epochs, MixUp 10% | Boosts diversity on small dataset; disable late to refine bboxes; light blending for regularization without unrealistic targets. |
| **Training Duration** | `epochs=100` | High ceiling with early stopping; typical convergence ~30–60 epochs. |


## Directory Structure

```
training/
├── configs/
│   ├── dataset.yaml              # Dataset paths & class definitions
│   └── model.yaml                # Training hyperparameters
├── data/
│   ├── raw -> <source_dataset>   # Symlink to original coin dataset
│   └── processed/                # Generated by prepare_dataset.py
│       ├── yolo/                 # Train + Val (Ultralytics format)
│       │   ├── images/{train,val}/
│       │   └── labels/{train,val}/
│       ├── test/                 # Held-out test set (COCO format)
│       │   ├── images/
│       │   └── _annotations.coco.json
│       └── splits.json           # Split metadata & statistics
├── experiments/                  # Auto-created per training run
│   └── <timestamp>_<name>/
│       ├── model.yaml            # Frozen config snapshot
│       ├── dataset.yaml          # Frozen dataset config
│       ├── summary.json          # Checkpoint paths & final metrics
│       └── train/
│           ├── args.yaml         # Ultralytics resolved arguments
│           ├── weights/
│           │   ├── best.pt       # Best validation mAP
│           │   └── last.pt       # Final epoch
│           └── ...               # Training curves, plots
├── notebooks/
│   └── 01_data_analysis_and_split_rationale.ipynb
├── scripts/
│   ├── prepare_dataset.py        # 3-way split + COCO→YOLO conversion
│   ├── train.py                  # Fine-tuning entry point
│   ├── evaluate.py               # Evaluation using project's eval module
│   └── export_model.py           # Export best checkpoint to artifacts/
└── README.md
```

## Configuration

Edit `configs/model.yaml` for training hyperparameters (epochs, learning rate, augmentation).
Edit `configs/dataset.yaml` for dataset paths and class definitions.

## Evaluation

The `evaluate.py` script reuses the project's evaluation module, giving you the full
metrics suite (mAP, counting, geometric proxies, failure analysis) with structured
artifact output to `artifacts/evaluation/`.

```bash
# Final reporting (held-out test set — use this for reporting)
python scripts/evaluate.py <model_path> --test

# Custom evaluation (e.g., on full dataset or specific subset)
python scripts/evaluate.py <model_path> --data-dir <images_dir> --annotations <coco_json>
```
